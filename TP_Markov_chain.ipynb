{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP-Markov-chain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKTsGfizabDd"
      },
      "source": [
        "# **1-Recherche du dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoQD-VllbCCT"
      },
      "source": [
        "je vais utiliser deux modules de python:\n",
        "\n",
        "**-requests** : je vais l'utiliser pour envoyer la requette https get afin d'obtenir la page html qui contient notre texte.\n",
        "\n",
        "**-bs4** :  ce module va me permettre d'extraire le texte contenue dans la page html.\n",
        "\n",
        "j'ai choisi une page web qui contient un texte qui long afin qu'il soit suffisant pour le diviser en 2 , une partie pour l'apprentissage et une autre pour le test ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwuqz2VRdx5T"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import string\n",
        "html=requests.get(\"https://whiletrue.neocities.org/lte.html\")\n",
        "html=html.text\n",
        "clean_text=''.join(BeautifulSoup(html,\"html.parser\").stripped_strings)\n",
        "lower_case_text=clean_text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3I5hPjJeGy6"
      },
      "source": [
        "# 2-Prétraitement du texte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64luliY4fkMI"
      },
      "source": [
        "dans cette partie j'ai éliminé les poctuations qui existe dans le texte ainsi que d'autre caractères comme : ð , ¾ comme j'ai aussi remplacé les caractères qui ont un accent circonflexe par des caractères sans accent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtX6y3UueUJD"
      },
      "source": [
        "punctuations = '''ð¾º°\\x82½!()¼\\x83-—³\\r\\n\\x88\\x92[]\\x9c{}©\\x81“”;\\x80:¸\\x9d'’\"\\,'‘'<>±.µ\\x99/?@+#$%^&*_~\\x981234567890\\x84²'''\n",
        "no_punct_text = \"\"\n",
        "for char in lower_case_text:\n",
        "   if char not in punctuations:\n",
        "       no_punct_text = no_punct_text + char\n",
        "no_punct_text=no_punct_text.replace('â','a')\n",
        "no_punct_text=no_punct_text.replace('ñ','n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6FVB_LhgMAe"
      },
      "source": [
        "#3-Division du texte en 2 parties (apprentissage et test)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn78GcH3grPi"
      },
      "source": [
        "train_text=no_punct_text[:67700]\n",
        "test_text=no_punct_text[67700:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDO1IPb9ipHB"
      },
      "source": [
        "#4-chaine de markov d'ordre 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDcNmYSajG4K"
      },
      "source": [
        "dans cette étape je vais construire la matrice des probabilités de transition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZPURvH0kKPd"
      },
      "source": [
        "# retourne l'indice du caractère dans la matrice des probabilités\n",
        "chars=[chr(i) for i in range(97,123)]\n",
        "chars.append(' ')\n",
        "def get_char_index(char):\n",
        "  return chars.index(char)\n",
        "# construction de la matrice des probabilités:\n",
        "def markov_chain_order_1(train_text):\n",
        "  # la matrice des transitions\n",
        "  M=np.array(np.zeros((27,27)))\n",
        "  for x in range(len(train_text)-1):\n",
        "    i=get_char_index(train_text[x])\n",
        "    j=get_char_index(train_text[x+1])\n",
        "    M[i][j]+=1\n",
        "  # division de chaque ligne par la somme des élements de cette ligne pour qu'il soit une probabilité\n",
        "  sum=np.sum(M,axis=1)\n",
        "  for i in range(len(M)):\n",
        "      if sum[i]!=0:\n",
        "          M[i]=M[i]/sum[i]\n",
        "  return M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFSzgQUanC8_"
      },
      "source": [
        "#5-évaluation du modèle de modèle de Markov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIagrBLUnehW"
      },
      "source": [
        "def model_evaluation(test_text,M):\n",
        "  score=0\n",
        "  for x in range(len(test_text)-1):\n",
        "    sc=0\n",
        "    i=get_char_index(test_text[x])\n",
        "    j=get_char_index(test_text[x+1])\n",
        "    arr=[]\n",
        "    arr=M[i].tolist()\n",
        "    ind=chars.index(np.random.choice(chars,p=M[i]))\n",
        "    tentative=1\n",
        "    sc+=M[i][j]\n",
        "    while(chars[ind]!=chars[j]):\n",
        "        tentative+=1\n",
        "        arr[ind]=-1\n",
        "        ind = chars.index(np.random.choice(chars,p=M[i]))\n",
        "    sc=sc/tentative\n",
        "    score+=sc\n",
        "  return score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtbwU9i8wxqc",
        "outputId": "b7780090-5a84-4137-d528-d14646687453"
      },
      "source": [
        "M=markov_chain_order_1(train_text)\n",
        "score=model_evaluation(test_text,M)\n",
        "print(\"score : \",score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score :  33.69616661068976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xrk6jeFynde"
      },
      "source": [
        "l'évaluation du modèle de markov nous a donné un score de 34.51"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFQ7G17qyzrc"
      },
      "source": [
        "#6-modèle de markov d'ordre supérieur (d'ordre n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROT6kr44y8rN"
      },
      "source": [
        "on va suivre les memes étapes qu'auparavant sauf que maintenant les états de la chaines ne sont plus des caractères , elles sont des mots."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0-_bggn0aCw"
      },
      "source": [
        "d'abord on doit créer un tableau qui contient les combinaisons de n caractères afin de faciliter l'obtention de l'indice d'une combinaison:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-osodj-3-5LT"
      },
      "source": [
        "je vais mettre tout d'abord n=3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzAkFgXJ1Ftl"
      },
      "source": [
        "\n",
        "def char_combination(n):\n",
        "  strs=[]\n",
        "  for item in itertools.product(chars, repeat=n):\n",
        "    string=''.join(item)\n",
        "    strs.append(string)\n",
        "  return strs\n",
        "def get_str_index(string,strs):\n",
        "  return strs.index(string)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lnzh4_g2xLj"
      },
      "source": [
        "#construction de la matrice des transitions:\n",
        "def markov_chain_order_n(train_text,n):\n",
        "  strs=char_combination(n)\n",
        "  Mn=np.array(np.zeros((27**n,27)))\n",
        "  for x in range(len(train_text)-n):\n",
        "    i=get_str_index(train_text[x:x+n],strs)\n",
        "    j=get_char_index(train_text[x+n])\n",
        "    Mn[i][j] += 1\n",
        "  # division de chaque ligne par la somme des élements de cette ligne pour qu'il soit une probabilité\n",
        "  sum=np.sum(Mn,axis=1)\n",
        "  for i in range(len(Mn)):\n",
        "      if sum[i]!=0:\n",
        "          Mn[i]=Mn[i]/sum[i]\n",
        "  return Mn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEBEtuAG5-oo"
      },
      "source": [
        "#7-évaluation du modèle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKGwJpLl6DZH"
      },
      "source": [
        "def evaluate_markov_model(M,test_text,n):\n",
        "  score=0\n",
        "  strs=char_combination(n)\n",
        "  for x in range(len(test_text)-n):\n",
        "    sc=0\n",
        "    i=get_str_index(test_text[x:x+n],strs)\n",
        "    j=get_char_index(test_text[x+n])\n",
        "    arr=[]\n",
        "    arr=M[i].tolist()\n",
        "    ind = arr.index(max(arr))\n",
        "    tentative=1\n",
        "    sc+=M[i][j]\n",
        "    while(chars[ind]!=chars[j]):\n",
        "        tentative+=1\n",
        "        arr[ind]=-1\n",
        "        ind = arr.index(max(arr))\n",
        "    sc=sc/tentative\n",
        "    score+=sc\n",
        "  return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87VcwraM8c1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ff46b6-822c-4dce-972e-5a0135c39d0b"
      },
      "source": [
        "M=markov_chain_order_n(train_text,n=2)\n",
        "score=evaluate_markov_model(M,test_text,n=2)\n",
        "print(\"score : \",score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score :  112.17816972080074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "789npsY5_B6D"
      },
      "source": [
        "l'évaluation du modèle de markov d'ordre 3 nous a donnée un score de 112.17 qui est très grand du score donné par le modèle d'ordre 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZON9DLI_Vp-"
      },
      "source": [
        "# 8-Modélisation du texte comme succession des mots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLlsJoHkcSQy"
      },
      "source": [
        "dans cette section les états sont les mots du texte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmwjBCQ0cjJd"
      },
      "source": [
        "def get_words_of_text(train_text):\n",
        "  words=train_text.split()\n",
        "  #pour avoir des mots uniques:\n",
        "  words=list(dict.fromkeys(words))\n",
        "  return words\n",
        "def get_word_combination(n,words):\n",
        "  strs=[]\n",
        "  for item in itertools.product(words, repeat=n):\n",
        "    string=''.join(item)\n",
        "    strs.append(string)\n",
        "  return strs\n",
        "def get_word_index(words_combination,word):\n",
        "  return words_combination.index(word)\n",
        "def get_words_index(words_combination,words):\n",
        "  return words_combination.index(words)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lpr29yQdaCH"
      },
      "source": [
        "def words_markov_model_order_n(train_text,n=1):\n",
        "  words=get_words_of_text(train_text)\n",
        "  spaced_words=[]\n",
        "  for i in range(len(words)):\n",
        "    spaced_words.append(words[i]+\" \")\n",
        "  length=len(words)\n",
        "  if n!=1:\n",
        "    words_combination=get_word_combination(n,spaced_words)\n",
        "  else:\n",
        "    words_combination=words\n",
        "  M=np.zeros((length**n,length))\n",
        "  empty=\" \"\n",
        "  splitted_text=train_text.split()\n",
        "  for x in range(len(splitted_text)-n):\n",
        "    i=get_words_index(words_combination,empty.join(splitted_text[x:x+n]))\n",
        "    j=get_word_index(words,splitted_text[x+n])\n",
        "    M[i][j]+=1\n",
        "  # division de chaque ligne par la somme des élements de cette ligne pour qu'il soit une probabilité\n",
        "  sum=np.sum(M,axis=1)\n",
        "  for i in range(len(M)):\n",
        "      if sum[i]!=0:\n",
        "          M[i]=M[i]/sum[i]\n",
        "  return M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LOkul3FBcRz"
      },
      "source": [
        "# 9-Géneration du texte avec un modèle de markov"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_Y5ZVj-Bm15"
      },
      "source": [
        "def text_generation(M,length,start,n):\n",
        "  strs=char_combination(n)\n",
        "  text=start\n",
        "  string=start\n",
        "  for i in range(length):\n",
        "    index=get_str_index(string,strs)\n",
        "    prob=M[index]\n",
        "    try:\n",
        "      char_next=np.random.choice(chars,p=prob)\n",
        "    except(ValueError):\n",
        "      char_next=np.random.choice(chars)\n",
        "    text=text+char_next\n",
        "    string=text[i+1:]\n",
        "  return text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UTuIRyluJYn"
      },
      "source": [
        "n_max=4\n",
        "Ms=[]\n",
        "# pour avoir les matrices de transition des 5 modèles:\n",
        "for i in range(1,n_max+1):\n",
        "  Ms.append(markov_chain_order_n(train_text,i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zSBd6Q1u5Jx",
        "outputId": "4562baa2-15fe-4d01-ce76-a00f862e4b0f"
      },
      "source": [
        "start=\"i can\"\n",
        "length=200\n",
        "for i in range(1,n_max+1):\n",
        "  text=text_generation(Ms[i-1],length,start[:i],i)\n",
        "  print(\"----------------the text generated by the model of order :\",i,\"----------------\")\n",
        "  print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------the text generated by the model of order : 1 ----------------\n",
            "itins heatisighonat whe lit thanguelsed bla  g a dasa os sthe ar mong tifo g tyont odanore ho tthe giting ractsto juem s ung fly me thine myinase barean t be we fit dag urle ing eadn tell i futheng wr \n",
            "----------------the text generated by the model of order : 2 ----------------\n",
            "i som sheret days a smake my i lted a durecookmadere the evessic it rit meher ter hat this this spefers tharks up my mone thoulat sent funding only dre beticiall ter of causeembit hatime vied yof yout e\n",
            "----------------the text generated by the model of order : 3 ----------------\n",
            "i chardent howed the typing abouture top editiesame i dont toast just on i works still of differse ill as i maths technice not they havent pastill king and closite yournerpost stand them prevery good it \n",
            "----------------the text generated by the model of order : 4 ----------------\n",
            "i can made cringy store i dont know what anothere cring my dad so this eative all of this ltes think i made of furries nowa iam march   sorry computer screensaver a cringy viesa explained off first text i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSRpb-03tMcF"
      },
      "source": [
        "def words_text_generation(M,length,start,n=1):\n",
        "  word=start\n",
        "  text=start\n",
        "  for i in range(length):\n",
        "    words=get_words_of_text(train_text)\n",
        "    combinations=get_word_combination(n,words)\n",
        "    index=get_word_index(combinations,word)\n",
        "    prob=M[index]\n",
        "    next_word=np.random.choice(combinations,p=prob)\n",
        "    text+=\" \"+next_word\n",
        "    word=next_word\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilYy-YtLxXS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6c10a7-ed22-481b-e00f-92ceabbffb78"
      },
      "source": [
        "M=words_markov_model_order_n(train_text)\n",
        "start=\"the\"\n",
        "length=200\n",
        "text=words_text_generation(M,length,start)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the days when it at home from a sesame street piano is reduced to her lte except the t its being a furry by talking about now my part of them in this lte its a countdown on the lte is way to have to write a world record three months ago i was yet but we take a bomb thats quite nice too boring part of people are on there and try to happen okay i didnat know ill be an important message theres not why because i see if my language is this webpage has an hour plus the cyrillic you knew i need a language my sister sometimes but you dont think i did a story once but i mean i once made by the exclamation point but its on my sister is even if i believe was a users computerconsolewhatever session is write as much as possible in this lte out as i dont think of the start to zula the country according to increase your ltes flamingchicken lte fact it was in this language to get from march and dont know one copy because of this be the fact you never finished it properly but i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cBBhc7w-_R6"
      },
      "source": [
        "# 10-Comparaison et conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRtgP1vj_FPj"
      },
      "source": [
        "le texte géneré par le modèle de markov d'ordre n est meilleur et bien compréhensible que celui géneré par les modèles d'ordre n-1,n-2,...,1 et il a un score plus grand .malheureusement on peut pas aller vers un ordre qui est supérieur à 4 car on est limité par la taille de la mémoire et aussi on a la taille de la matrice des transitions qui grandit avec l'ordre donc ce qui permet à la phase d'apprentissage de prendre beaucoup de temps et meme parfois la session peut se bloquer.\n",
        "\n",
        "la version des mots est la meilleure puisque un modèle d'ordre 1 génére des mots qui sont compréhensible mais meme ici malheuresement on ne peut pas dépasser n=1, si l'on dépasse ca va prendre beacoups de temps et la session se bloque vers la fin."
      ]
    }
  ]
}